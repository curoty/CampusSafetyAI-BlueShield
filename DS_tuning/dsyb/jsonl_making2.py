import json
import random
from datetime import datetime, timedelta
import itertools


class ProjectTrainingDataGenerator:
    def __init__(self):
        self.synonyms = {
            "开发团队": ["开发小组", "项目团队", "技术团队", "研发队伍", "开发人员", "项目组", "技术小组", "开发阵容"],
            "大二学生": ["大学二年级学生", "二年级本科生", "大二在读生", "大二同学", "二年级同学", "大二学子"],
            "人工智能专业": ["AI专业", "智能科学与技术专业", "人工智能方向", "AI技术专业", "人工智能学科"],
            "扎实的": ["坚实的", "牢固的", "深厚的", "过硬的", "扎实的", "熟练的", "专业的"],
            "Python": ["Python编程", "Python语言", "Python开发", "Python技术", "Python程序"],
            "机器学习": ["ML技术", "机器学习算法", "智能算法", "AI算法", "机器学习方法"],
            "大模型部署": ["大模型应用部署", "大模型上线", "大模型工程化", "模型部署实施"],
            "微调": ["调优", "优化适配", "参数调整", "模型微调", "精细调整"],
            "摔倒检测": ["跌倒检测", "摔倒识别", "跌倒识别", "摔倒监测", "跌倒监测"],
            "YOLO": ["YOLO模型", "YOLO检测器", "YOLO识别模型", "YOLO算法", "目标检测模型"],
            "DeepSeek": ["DeepSeek大模型", "DeepSeek-7B", "DS7b模型", "DS大模型", "语言模型"],
            "状态机": ["状态判断机", "状态逻辑器", "状态控制器", "状态管理机", "计时状态机"],
            "RAG": ["RAG记忆", "RAG存储层", "检索增强生成", "RAG系统", "记忆检索层"],
            "告警": ["警报", "报警", "预警通知", "告警信息", "危险通知"],
            "置信度": ["可信度", "置信分数", "可靠度", "置信水平", "可信分数"],
            "助手": ["助理", "辅助者", "帮手", "服务者", "支持者"],
            "监控": ["监测", "监视", "观察", "检测", "巡查"],
            "帧": ["画面帧", "图像帧", "视频帧", "检测帧"],
            "比例": ["占比", "比率", "百分比", "份额", "比重"],
            "系统": ["平台", "体系", "方案", "解决方案", "系统平台"],
            "功能": ["能力", "作用", "性能", "效用", "功能特性"],
            "技术": ["科技", "技术手段", "技术方案", "技术方法", "技术实现"],
            "项目": ["系统", "平台", "方案", "工程", "项目系统"],
            "检测": ["识别", "监测", "感知", "发现", "侦测"],
            "告警": ["报警", "警报", "预警", "提醒", "通知"],
            "实时": ["即时", "立即", "马上", "即刻", "及时"],
            "历史": ["过往", "以前", "先前", "旧时", "过去"],
            "查询": ["查找", "搜索", "检索", "查看", "调取"],
            "存储": ["保存", "存储", "保留", "存档", "记录"],
            "分析": ["解析", "处理", "研判", "分析处理", "数据分析"]
        }

        # 统一的指令模板
        self.alert_instruction = "你是本项目的告警助手，根据输入的高危信息，进行告警并输出到最终结果到前端用户"
        self.qa_instruction = "你是本项目的AI助手，请根据你的知识回答用户的问题"

        # AI助手身份相关问答 - 扩展至20个问题变种和10个回答变种
        self.identity_questions = {
            "assistant_identity": {
                "core_question": "AI助手身份",
                "question_variations": [
                    "你好",
                    "你是谁？",
                    "给我介绍一下你自己",
                    "你是什么AI？",
                    "你的身份是什么？",
                    "请做个自我介绍",
                    "你叫什么名字？",
                    "你能做什么？",
                    "你的职责是什么？",
                    "简单介绍一下你",
                    "嗨，你好",
                    "你是谁开发的？",
                    "你的功能有哪些？",
                    "你是什么类型的助手？",
                    "你的定位是什么？",
                    "介绍一下你的背景",
                    "你的作用是什么？",
                    "你是做什么的？",
                    "请描述一下你自己",
                    "你的服务内容有哪些？",
                    "你好，能介绍一下自己吗？",
                    "请问您是谁？",
                    "可以自我介绍一下吗？",
                    "你的角色是什么？",
                    "你在这个项目中负责什么？",
                    "请告诉我你的基本信息",
                    "你是什么类型的AI？",
                    "你的主要功能是什么？",
                    "你能为我提供什么服务？",
                    "简单说明一下你的身份"
                ],
                "answer_variations": [
                    "你好！我是摔倒检测告警助手，基于DeepSeek-7B大模型开发。我专门负责监控摔倒高危事件、生成告警信息，并回答关于本项目的各种问题。很高兴为您服务！",
                    "我是本项目的智能告警助手，专注于实时安全监护。我能够处理摔倒检测告警、查询历史事件记录，并解答关于项目团队、技术实现、功能模块等方面的疑问。",
                    "您好！我是摔倒检测系统的AI助手，由三位河南高校AI专业学生开发。我具备实时告警生成、历史数据查询和项目咨询三大核心能力，随时为您提供安全监护服务。",
                    "我是基于DeepSeek-7B大模型定制的摔倒检测告警助手。我的主要职责是：监控人员安全状态、生成高危事件告警、管理历史记录数据，并作为项目的信息咨询接口。",
                    "你好！我是这个摔倒检测项目的专属AI助手。我融合了计算机视觉检测与大语言模型智能，既能实时处理安全告警，又能智能回答各类项目相关问题，为您提供全方位的服务。",
                    "我是智能安全监护助手，专门为摔倒检测项目而生。我负责从视频分析到告警推送的整个流程，同时还能作为您的项目顾问，解答技术细节和使用方法等问题。",
                    "您好！我是项目的全栈AI助手，既处理后端的安全检测逻辑，又提供前端的智能交互服务。无论是实时告警还是历史查询，我都能快速准确地响应您的需求。",
                    "我是基于DeepSeek技术打造的摔倒检测专用助手。我的特色在于结合了YOLO视觉检测的准确性和大语言模型的交互智能，为您提供专业可靠的安全监护服务。",
                    "你好！我是这个系统的AI核心，负责协调视频分析、状态判断和告警生成的全流程。同时我也是您的智能顾问，可以详细解答项目的技术实现和功能特点。",
                    "我是项目的智能守护者，专注于人员安全监测。我具备实时风险识别、智能告警生成、历史数据管理和项目知识咨询四大能力，全力保障监控区域的安全。",
                    "您好！我是摔倒检测系统的AI助手，专门负责安全监控和告警处理。我可以帮您查询项目信息、处理安全事件，并提供技术咨询服务。",
                    "我是本项目的智能安全助手，基于先进的AI技术开发。我能够实时监测人员安全状态，及时生成告警信息，并解答您关于系统使用的各种问题。",
                    "你好！我是专为摔倒检测设计的AI助手。我整合了计算机视觉和自然语言处理技术，既能进行智能监控，又能提供友好的对话交互体验。",
                    "我是您身边的安全监护专家，基于DeepSeek大模型构建。我负责实时分析监控画面，识别潜在风险，并在必要时发出告警通知。",
                    "您好！我是摔倒检测平台的AI核心。我具备多重能力：实时视频分析、风险评估判断、智能告警生成和全方位信息咨询服务。"
                ]
            }
        }

        # 定义完整的15个核心问题及其变种 - 扩展至20个问题变种和10个回答变种
        self.core_questions = {
            "team_intro": {
                "core_question": "团队介绍",
                "question_variations": [
                    "项目开发团队是什么情况？",
                    "给我介绍一下本项目的开发者团队。",
                    "谁开发了这个摔倒检测项目？团队背景如何？",
                    "开发团队有几人？专业和技术基础怎样？",
                    "这个项目的开发者是谁？能介绍一下吗？",
                    "团队构成是怎样的？成员有什么技术背景？",
                    "开发人员都是什么背景？技术水平如何？",
                    "项目团队有多少人？他们的专业方向是什么？",
                    "能详细说说开发团队的情况吗？",
                    "团队成员都是什么学历和专业？",
                    "开发这个系统的是哪些人？他们有什么能力？",
                    "请介绍一下项目开发团队",
                    "项目的开发人员情况如何？",
                    "团队的技术实力怎么样？",
                    "开发者团队有多少成员？",
                    "开发团队的专业背景是什么？",
                    "项目是由谁开发的？",
                    "团队成员的技能水平如何？",
                    "开发团队的教育背景怎样？",
                    "请详细说明开发团队情况",
                    "团队的技术专长有哪些？"
                ],
                "answer_variations": [
                    "本项目由三个河南高校人工智能专业的大二学生开发，他们具备扎实的Python、机器学习及大模型部署微调基础，能独立完成项目全流程开发。",
                    "开发这个项目的是三位河南高校的大二学生，专业均为人工智能，在Python编程、机器学习技术，以及大模型的部署与微调方面有扎实功底。",
                    "项目团队由三名河南高校人工智能专业大二学生组成，成员熟练掌握Python、机器学习，且在大模型部署和LoRA微调等技术上有丰富实操经验。",
                    "三位来自河南高校AI专业的大二同学共同开发了本项目，他们在Python开发、机器学习算法和大模型优化部署方面具备扎实的技术能力。",
                    "开发团队是三位人工智能专业的二年级本科生，来自河南高校，精通Python编程、机器学习理论，并拥有大模型微调与部署的实践经验。",
                    "本项目开发团队由三名河南高校AI专业大二学生构成，他们在Python编程、机器学习算法、大模型技术等方面有深厚的技术积累。",
                    "团队由三位河南高校人工智能方向的大二同学组成，具备扎实的编程基础和AI技术理解，能够独立完成复杂系统的设计与实现。",
                    "开发小组包括三名河南高校AI专业二年级学生，他们在Python开发、机器学习实践和大模型应用方面有丰富的项目经验。",
                    "项目研发团队是三位来自河南高校的大二AI专业学生，熟练掌握Python技术栈和机器学习框架，具备全栈开发能力。",
                    "本项目技术团队由三名河南高校人工智能专业大二学生牵头，他们在Python编程、AI算法和大模型优化方面有扎实的专业基础。"
                ]
            },

            "core_function": {
                "core_question": "核心功能",
                "question_variations": [
                    "项目主要能实现什么功能？",
                    "这个摔倒检测项目的核心作用是什么？",
                    "项目有哪些关键功能模块？",
                    "系统的主要功能有哪些？",
                    "这个检测系统能做什么？",
                    "项目的核心价值体现在哪里？",
                    "主要实现了哪些检测功能？",
                    "系统具备什么样的功能特点？",
                    "用户通过这个项目能获得什么服务？",
                    "功能模块都包括哪些内容？",
                    "给我介绍一下本项目的功能。",
                    "系统的主要作用是什么？",
                    "这个平台有什么功能？",
                    "项目能提供哪些服务？",
                    "核心功能特点有哪些？",
                    "系统的主要能力是什么？",
                    "这个解决方案有什么功能？",
                    "平台的功能特性有哪些？",
                    "请详细说明系统功能",
                    "项目的主要功能模块是什么？",
                    "系统能实现哪些具体功能？"
                ],
                "answer_variations": [
                    "项目核心功能为智能摔倒检测与高危告警：通过YOLO模型实时检测视频流中人体状态，结合状态机逻辑判断摔倒风险，当10秒内Fall Detected帧比例≥80%时，触发DeepSeek-7B大模型生成标准化告警信息并推送至用户；同时支持Web端实时监控查看、历史告警查询、大模型交互及1-2天监控视频存储。",
                    "系统核心功能包括实时摔倒检测、智能风险评估、自动告警推送和交互查询：利用YOLO识别人员状态，状态机基于帧比例验证风险持续性，大模型生成自然语言告警，Web界面提供全方位监控管理。",
                    "主要功能模块：1)实时视频分析检测 2)状态风险评估(基于帧比例) 3)智能告警生成 4)Web可视化界面 5)历史数据管理 6)智能对话交互，形成完整的摔倒监测解决方案。",
                    "功能体系：前端实时显示检测画面，后端进行状态识别与风险评估(帧比例分析)，大模型处理高危事件生成告警，RAG层存储历史数据，支持用户多维度查询与交互。",
                    "核心功能涵盖：视频流处理、人体状态检测、风险逻辑判断(帧比例≥80%)、告警信息生成、前端展示交互、历史数据存储六大方面，提供端到端的摔倒安全监护服务。",
                    "项目功能架构：基于YOLO的实时状态检测、基于帧比例的状态机风险评估、DeepSeek大模型的智能告警生成、Web前端的可视化展示、RAG记忆层的历史数据管理五大核心功能。",
                    "系统能力：实时视频流分析、人体姿态识别、摔倒风险判断(帧比例阈值)、智能告警推送、历史事件查询、AI对话交互六大功能模块，构建完整安全监护体系。",
                    "平台功能：1)实时监控与检测 2)风险评估与分析 3)智能告警生成 4)前端可视化 5)历史数据追溯 6)智能咨询服务，为用户提供全方位安全保障。",
                    "核心功能组成：视频采集处理、目标检测识别、状态风险评估、告警信息生成、前端界面展示、历史数据存储、智能对话交互七大功能组件。",
                    "系统功能特色：基于计算机视觉的实时检测、基于帧比例算法的风险评估、基于大模型的智能告警、基于Web的可视化界面、基于RAG的数据管理五大功能特性。"
                ]
            },

            "tech_stack": {
                "core_question": "技术栈",
                "question_variations": [
                    "项目用到了哪些关键技术？",
                    "开发这个项目依赖哪些技术手段？",
                    "项目的技术栈包含哪些内容？",
                    "采用了什么技术方案？",
                    "技术实现基于哪些工具和框架？",
                    "系统架构用了哪些技术？",
                    "核心技术组件有哪些？",
                    "技术选型是怎样的？",
                    "开发过程中使用了什么技术？",
                    "项目的技术基础是什么？",
                    "给我介绍一下本项目的实现框架。",
                    "给我介绍一下本项目的业务逻辑",
                    "技术架构包含哪些部分？",
                    "使用了哪些技术工具？",
                    "项目的技术组成是什么？",
                    "技术方案有哪些特点？",
                    "系统基于什么技术构建？",
                    "核心技术有哪些？",
                    "技术实现方案是什么？",
                    "请详细说明技术架构",
                    "项目采用了哪些先进技术？"
                ],
                "answer_variations": [
                    "项目核心技术栈涵盖多领域：计算机视觉(OpenCV视频流读取、YOLO目标检测)、大模型技术(DeepSeek-7B大模型、4bit量化降显存、LoRA微调高效适配)、RAG记忆层(历史数据存储)、状态机逻辑编程(基于帧比例判断)及Web前后端开发框架。",
                    "技术架构：OpenCV处理视频输入，YOLO进行状态识别，状态机实现基于帧比例的风险逻辑，DeepSeek-7B生成告警，4bit量化优化资源，LoRA微调适配任务，RAG管理历史数据，Flask+前端完成展示。",
                    "核心技术：计算机视觉层面的OpenCV+YOLO组合，大模型层面的DeepSeek-7B+4bit量化+LoRA微调，数据层面的RAG记忆存储，业务逻辑层的状态机帧比例判断，以及展示层的Web前后端技术。",
                    "技术体系包含：视频处理技术(OpenCV)、目标检测技术(YOLO)、风险判断技术(状态机帧比例分析)、自然语言技术(DeepSeek)、优化技术(4bit量化+LoRA)、存储技术(RAG)、展示技术(Web框架)七大技术支柱。",
                    "采用的技术方案：YOLO负责实时检测，状态机进行帧比例逻辑验证，DeepSeek处理告警生成，4bit量化降低硬件要求，LoRA微调提升适应性，RAG实现智能记忆，Web技术完成用户交互。",
                    "项目技术架构：前端采用Web技术实现可视化界面，后端使用Python+Flask处理业务逻辑，计算机视觉部分基于OpenCV+YOLO，AI部分基于DeepSeek-7B+4bit量化+LoRA微调，数据层使用RAG记忆存储。",
                    "技术组成：1)视频处理-OpenCV 2)目标检测-YOLO 3)风险评估-状态机帧比例算法 4)自然语言-DeepSeek大模型 5)优化技术-4bit量化+LoRA 6)数据存储-RAG 7)界面展示-Web前端。",
                    "技术方案特点：采用多技术融合架构，计算机视觉处理视频流，状态机算法评估风险，大模型生成告警，轻量化技术优化性能，RAG实现智能记忆，Web技术提供友好界面。",
                    "核心技术栈：Python编程语言、OpenCV视频处理、YOLO目标检测、状态机风险评估、DeepSeek大模型、4bit量化压缩、LoRA微调优化、RAG记忆存储、Web前后端开发。",
                    "技术实现：基于OpenCV的视频采集，YOLO的人体状态识别，状态机的帧比例风险评估，DeepSeek的告警生成，4bit量化的模型压缩，LoRA的高效微调，RAG的历史数据管理。"
                ]
            },

            "workflow": {
                "core_question": "工作流程",
                "question_variations": [
                    "项目如何完成摔倒检测到告警的全过程？",
                    "摔倒检测的具体流程是什么？",
                    "从视频读取到告警推送的步骤有哪些？",
                    "系统的工作流程是怎样的？",
                    "检测告警的完整过程是什么？",
                    "从识别到告警经历了哪些步骤？",
                    "数据处理流程是怎样的？",
                    "系统运行的具体步骤是什么？",
                    "整个检测过程如何实现？",
                    "工作流程包含哪些环节？",
                    "给我介绍一下本项目的业务逻辑",
                    "系统的处理流程是什么？",
                    "从输入到输出的完整流程？",
                    "数据处理的全过程？",
                    "系统如何工作？",
                    "运行机制是怎样的？",
                    "请描述系统工作流程",
                    "处理步骤有哪些？",
                    "完整的业务流程是什么？",
                    "系统如何实现检测到告警？",
                    "工作流程的详细步骤？"
                ],
                "answer_variations": [
                    "全流程分为四步：视频采集(OpenCV间隔采样)→状态检测(YOLO识别分类)→逻辑判断(状态机统计10秒内Fall Detected帧比例≥80%)→告警生成(DeepSeek格式化输出)→推送存储(前端展示+RAG记忆)，形成完整处理闭环。",
                    "工作流程：摄像头视频流→帧采样处理→YOLO状态识别→状态机帧比例风险评估→高危事件格式化→大模型告警生成→前端实时推送→历史数据存储，各环节紧密衔接。",
                    "处理流程：1)视频输入与采样 2)目标检测与分类 3)状态帧比例持续判断 4)告警信息生成 5)结果推送展示 6)数据持久化存储，实现从感知到决策的全链条处理。",
                    "系统流程：采集层获取视频，检测层识别状态，逻辑层验证帧比例风险，生成层创建告警，展示层推送给用户，存储层保留历史，各层协同完成摔倒监测任务。",
                    "完整流程：视频源→帧抽取→目标识别→状态分类→帧比例判断→提示生成→告警输出→前端显示→数据存档，每个环节都有相应的技术组件支撑。",
                    "业务流程：视频采集→帧采样→目标检测→状态识别→风险评估→事件确认→告警生成→前端推送→数据存储，形成端到端的处理流水线。",
                    "工作流程详解：1)视频流采集与预处理 2)YOLO模型目标检测 3)状态分类与置信度过滤 4)状态机帧比例风险评估 5)高危事件格式化 6)大模型告警生成 7)前端实时展示 8)RAG数据存储。",
                    "系统运行流程：开始→视频输入→帧采样→YOLO检测→状态判断→帧比例统计→风险评估→事件确认→告警生成→前端推送→数据记录→结束，循环执行。",
                    "处理流程步骤：视频采集→图像预处理→目标检测→状态分类→帧比例分析→风险判定→事件格式化→大模型处理→告警输出→前端展示→历史存储。",
                    "完整工作流：视频源输入→OpenCV处理→YOLO识别→状态机分析→DeepSeek生成→前端显示→RAG存储，七大步骤实现从感知到决策的完整链路。"
                ]
            },

            "web_function": {
                "core_question": "Web前端功能",
                "question_variations": [
                    "网页端能实现哪些操作？",
                    "Web界面有什么功能？",
                    "用户通过前端可以做什么？",
                    "前端页面提供哪些功能？",
                    "Web端的主要界面有哪些？",
                    "用户能在网页上完成什么操作？",
                    "前端系统包含哪些模块？",
                    "Web应用的功能特点是什么？",
                    "通过浏览器能实现哪些监控功能？",
                    "用户界面支持哪些交互操作？",
                    "在前端页面，用户都可以进行什么操作？",
                    "Web平台的功能有哪些？",
                    "前端能做什么？",
                    "用户通过界面能完成什么？",
                    "Web端的功能特性？",
                    "前端操作包括哪些？",
                    "网页界面提供什么功能？",
                    "用户在前端可以做什么？",
                    "请介绍前端功能",
                    "Web应用的主要功能？",
                    "前端系统的能力有哪些？"
                ],
                "answer_variations": [
                    "Web前端包含四大核心功能：实时监控画面展示(叠加YOLO检测框、标签及置信度)、高危告警信息查看、DeepSeek大模型智能对话交互、1-2天历史监控视频查看(支持按时间筛选)。",
                    "前端功能体系：监控展示模块(实时画面+检测信息)、告警管理模块(实时与历史告警)、智能交互模块(大模型对话)、视频存档模块(历史录像查看)，四大模块协同工作。",
                    "用户通过Web前端可以：查看实时监控画面(包含检测框显示)、接收和处理告警信息、查询历史安全事件、与AI助手对话获取信息、回放过往监控录像，实现全方位管理。",
                    "Web界面功能：主监控区显示摄像头画面(含检测信息)，告警面板展示实时提醒，对话窗口支持智能问答，历史记录提供事件查询，布局清晰功能完善。",
                    "前端操作功能：画面监控(实时显示检测信息)、告警处理(接收与查询)、数据查询(历史事件统计)、智能助手(项目咨询与信息获取)、系统管理(基础设置调整)。",
                    "Web平台功能：实时视频监控界面、告警信息管理面板、历史数据查询页面、智能对话交互窗口、系统设置管理区域，五大功能区域构成完整前端体系。",
                    "前端系统能力：1)实时视频显示与检测可视化 2)告警信息接收与处理 3)历史事件查询与统计 4)智能对话与咨询服务 5)监控录像回放与查看。",
                    "用户界面功能：监控画面实时展示区、告警信息列表区、历史数据查询区、AI对话交互区、系统设置管理区，分区明确功能完善。",
                    "Web应用特性：实时监控可视化、告警信息即时推送、历史数据灵活查询、智能对话自然交互、视频回放便捷查看，五大特性提升用户体验。",
                    "前端功能组成：视频监控模块、告警管理模块、数据查询模块、智能交互模块、系统设置模块，五大模块构建完整的前端功能体系。"
                ]
            },

            "yolo_function": {
                "core_question": "YOLO模型功能",
                "question_variations": [
                    "YOLO模型在项目里负责什么？",
                    "YOLO的检测逻辑和结果有哪些？",
                    "项目中YOLO模型怎么工作？",
                    "目标检测模块的作用是什么？",
                    "YOLO在系统中承担什么角色？",
                    "检测模型的工作原理是什么？",
                    "YOLO如何识别人员状态？",
                    "目标检测的实现方式是什么？",
                    "YOLO模型的输出结果有哪些？",
                    "检测算法的工作机制是怎样的？",
                    "YOLO在系统中起什么作用？",
                    "目标检测如何实现？",
                    "YOLO模型的工作方式？",
                    "检测模块的功能是什么？",
                    "YOLO如何工作？",
                    "目标检测的逻辑是什么？",
                    "请介绍YOLO模型功能",
                    "检测算法如何运行？",
                    "YOLO在流程中的角色？",
                    "目标检测的实现原理？",
                    "YOLO模型的工作机制？"
                ],
                "answer_variations": [
                    "YOLO模型是核心状态感知模块：实时识别视频流中人体状态，基于自定义训练的Fall Detected、Normal、Resting三类标签进行检测，置信度大于0.75的结果才被采纳，输出四种结果(含无目标情况)，为状态机帧比例分析提供数据基础。",
                    "YOLO作用：对采样视频帧进行目标检测，分类识别摔倒、正常、静止三种人体状态，设定0.75置信度阈值过滤误判，通过间隔帧处理平衡性能与精度，为后续状态机帧比例统计提供准确的姿态识别数据。",
                    "YOLO工作流程：接收采样视频帧→执行目标检测(置信度阈值0.75)→输出分类结果(Fall Detected/Normal/Resting/No detections)→传递至状态机逻辑层进行帧比例统计，形成系统的感知前端。",
                    "检测模块功能：利用YOLO算法实时分析视频内容，准确识别人员活动状态，通过三类标签区分不同姿态，设置0.75置信度确保检测可靠性，为系统提供可信的状态识别能力。",
                    "YOLO实现：基于预训练模型进行迁移学习，针对摔倒检测场景微调优化，设定0.75置信度阈值保证准确性，实现高效准确的状态分类，通过帧采样策略保证实时性。",
                    "YOLO模型职责：作为系统的视觉感知核心，负责从视频流中提取人体状态信息，通过深度学习算法准确分类三种活动状态，为风险评估提供基础数据支撑。",
                    "目标检测机制：采用YOLO算法实现实时目标识别，基于卷积神经网络提取特征，通过边界框回归和分类预测，输出人体状态类别及置信度分数。",
                    "YOLO工作方式：对输入视频帧进行网格划分，每个网格预测边界框和类别概率，通过非极大值抑制筛选最佳检测结果，输出人体状态分类信息。",
                    "检测模块实现：基于YOLOv5架构构建目标检测模型，通过迁移学习在摔倒检测数据集上微调，实现高效准确的人体状态识别能力。",
                    "YOLO功能特性：实时性高、准确性好、支持多目标检测，通过置信度阈值过滤低质量检测，为系统提供可靠的状态感知数据。"
                ]
            },

            "state_machine": {
                "core_question": "状态机逻辑",
                "question_variations": [
                    "状态机在项目中起什么作用？",
                    "状态机如何判断是否触发告警？",
                    "状态机的工作流程是什么？",
                    "风险评估的逻辑是怎样的？",
                    "如何避免误报和漏报？",
                    "状态判断机制是什么？",
                    "计时逻辑如何工作？",
                    "风险验证的过程是什么？",
                    "如何确认真正的摔倒事件？",
                    "状态管理的实现方式是什么？",
                    "状态机的功能是什么？",
                    "风险评估如何实现？",
                    "状态判断的逻辑？",
                    "如何验证摔倒事件？",
                    "状态机的工作机制？",
                    "风险判断的原理？",
                    "请介绍状态机逻辑",
                    "如何确定真实摔倒？",
                    "状态验证的过程？",
                    "风险评估的算法？",
                    "状态机如何工作？"
                ],
                "answer_variations": [
                    "状态机是防误报核心组件：统计10秒窗口期内检测帧中Fall Detected的比例，当比例≥80%时确认为真实摔倒事件，触发后续告警流程。这种帧比例判断机制能有效过滤瞬时异常。",
                    "状态机逻辑：监听YOLO输出→统计10秒内Fall Detected帧比例→比例≥80%生成高危事件→传递大模型处理，通过帧比例分析确保只有持续存在的摔倒状态才会触发告警。",
                    "风险评估机制：通过状态机实现帧比例验证，统计10秒检测周期内摔倒状态的帧占比，仅当占比超过80%阈值才确认为高危事件，大幅减少误报提高系统可靠性。",
                    "状态机作用：作为逻辑过滤层，在YOLO检测结果基础上增加帧比例维度验证，要求摔倒状态在检测周期内持续存在(≥80%帧比例)才确认为有效事件，提升系统准确性。",
                    "工作流程：状态输入→帧比例统计→阈值判断→事件触发→结果输出，通过严谨的帧比例分析逻辑确保只有经过验证的高危事件才会触发告警响应。",
                    "状态机算法：基于时间窗口的帧比例统计方法，在10秒检测周期内计算Fall Detected帧的占比，通过80%阈值过滤瞬时误检，确保告警准确性。",
                    "风险评估逻辑：采用滑动窗口统计方法，实时计算当前时间点前10秒内的摔倒帧比例，当比例持续超过阈值时确认高风险状态。",
                    "状态验证机制：通过多帧连续分析替代单帧判断，要求摔倒状态在检测周期内持续出现，避免因瞬时动作或检测误差导致的误报警。",
                    "帧比例算法：在固定时间窗口内统计有效检测帧中Fall Detected的比例，通过阈值比较判断事件真实性，提高系统抗干扰能力。",
                    "状态机实现：基于环形缓冲区存储最近10秒的检测结果，实时计算摔倒帧比例，当比例超过设定阈值时触发告警流程。"
                ]
            },

            "deepseek_function": {
                "core_question": "DeepSeek模型功能",
                "question_variations": [
                    "DeepSeek-7B在项目里做什么？",
                    "大模型在项目中承担哪些角色？",
                    "DeepSeek如何参与告警流程？",
                    "语言模型在系统中的作用是什么？",
                    "DeepSeek负责哪些任务？",
                    "大模型如何生成告警信息？",
                    "DeepSeek在流程中的位置是什么？",
                    "语言模型承担什么功能？",
                    "DeepSeek如何处理高危事件？",
                    "大模型的工作机制是怎样的？",
                    "DeepSeek的作用是什么？",
                    "大模型在系统中的角色？",
                    "语言模型如何工作？",
                    "DeepSeek的功能有哪些？",
                    "大模型负责什么任务？",
                    "DeepSeek的工作方式？",
                    "请介绍DeepSeek功能",
                    "语言模型的作用？",
                    "大模型如何参与系统？",
                    "DeepSeek的处理流程？",
                    "大模型的工作逻辑？"
                ],
                "answer_variations": [
                    "DeepSeek-7B承担告警生成与智能交互双重核心角色：仅接收经逻辑层处理的高危信息(时间、地点、帧比例分析结果)，生成标准化告警文案推送前端；通过调用RAG记忆层的历史数据，响应用户查询并解答项目相关问题。",
                    "大模型功能：1)告警生成-接收格式化事件信息(含帧比例数据)输出自然语言告警；2)智能交互-基于RAG历史数据回答用户查询，如告警统计、事件详情、项目介绍等，提供全面的信息服务。",
                    "DeepSeek参与环节：在状态机确认高危事件后，接收包含时间、地点、帧比例分析的结构化数据，生成易懂的告警描述推送到前端，同时作为智能助手响应用户的各种咨询需求。",
                    "语言模型作用：将技术数据转化为用户友好的告警信息，提供自然语言交互接口，存储和检索历史事件记录，实现系统与用户之间的智能沟通桥梁。",
                    "DeepSeek工作机制：高危事件→格式化Prompt→大模型处理→自然语言输出→前端展示+RAG存储，同时支持用户对话查询，实现告警与交互的双重功能。",
                    "DeepSeek角色定位：作为系统的智能核心，既负责将结构化事件数据转化为自然语言告警，又承担用户交互界面的智能问答功能。",
                    "大模型实现：基于DeepSeek-7B架构，通过4bit量化压缩模型大小，使用LoRA技术进行任务特定微调，实现高效的告警生成和智能对话能力。",
                    "语言模型功能：1)告警文案生成 2)历史数据查询 3)项目信息咨询 4)技术问题解答 5)使用指导提供，五大功能提升系统智能化水平。",
                    "DeepSeek工作流程：接收结构化事件数据→解析关键信息→生成自然语言描述→输出告警文案→存储历史记录，同时处理用户查询请求。",
                    "大模型特性：基于Transformer架构，具备强大的自然语言理解和生成能力，通过微调适配摔倒检测场景，提供准确可靠的智能服务。"
                ]
            },

            "rag_function": {
                "core_question": "RAG记忆层",
                "question_variations": [
                    "RAG记忆层在项目中有什么用？",
                    "历史告警数据怎么存储和查询？",
                    "RAG层的具体功能是什么？",
                    "如何实现历史数据管理？",
                    "记忆存储模块的作用是什么？",
                    "数据持久化如何实现？",
                    "历史查询功能怎么工作？",
                    "RAG如何支持智能对话？",
                    "数据存储的结构是怎样的？",
                    "记忆检索的实现机制是什么？",
                    "RAG的作用是什么？",
                    "历史数据如何管理？",
                    "记忆层的功能？",
                    "数据存储如何实现？",
                    "RAG如何工作？",
                    "历史查询的实现？",
                    "请介绍RAG记忆层",
                    "数据管理机制？",
                    "记忆存储的功能？",
                    "RAG的实现原理？",
                    "历史数据查询机制？"
                ],
                "answer_variations": [
                    "RAG记忆层是项目的智能记忆核心：以JSON格式存储每条高危事件的关键信息(事件ID、发生时间、地点、帧比例分析结果、告警状态等)，为DeepSeek大模型提供历史上下文，支持用户查询统计和历史事件追溯。",
                    "RAG功能：结构化存储事件数据→建立高效检索索引→为大模型提供记忆支持→实现历史信息查询→支撑统计分析和智能问答，形成完整的数据管理链条。",
                    "数据管理：通过RAG系统将告警事件结构化存储，建立向量索引支持快速检索，为大模型对话提供准确的历史信息，实现智能化的数据查询和统计服务。",
                    "RAG实现：事件数据JSON格式化→向量化存储→相似性检索→上下文构建→大模型增强，为系统提供可靠的记忆能力和智能查询功能。",
                    "记忆层作用：持久化存储历史事件，建立检索优化机制，支撑大模型的历史感知能力，实现用户对过往安全事件的灵活查询和统计分析需求。",
                    "RAG架构：基于向量数据库构建检索增强生成系统，将历史事件数据向量化存储，支持相似性检索和语义查询，为大模型提供准确的上下文信息。",
                    "数据存储结构：采用JSON格式记录事件详情，包括时间戳、位置信息、帧比例数据、告警内容等字段，建立多维度索引支持快速查询。",
                    "记忆检索机制：基于向量相似度计算实现语义检索，支持按时间、地点、事件类型等多条件组合查询，返回相关的历史事件信息。",
                    "RAG工作流程：数据录入→向量化处理→索引构建→查询解析→相似度计算→结果排序→上下文构建→大模型增强，实现智能化的历史数据管理。",
                    "记忆层特性：支持结构化数据存储、提供高效检索能力、具备语义理解功能、实现历史上下文构建，四大特性提升系统智能化水平。"
                ]
            },

            "innovation": {
                "core_question": "技术创新性",
                "question_variations": [
                    "项目技术有哪些创新点？",
                    "这个项目的技术先进性体现在哪里？",
                    "相比同类项目，技术上有什么优势？",
                    "技术创新体现在哪些方面？",
                    "项目的技术亮点是什么？",
                    "有哪些独特的技术方案？",
                    "技术突破点在哪里？",
                    "创新性技术特征有哪些？",
                    "相比传统方案有什么改进？",
                    "技术上的独特之处是什么？",
                    "项目的创新点有哪些？",
                    "技术优势是什么？",
                    "创新特性有哪些？",
                    "技术亮点在哪里？",
                    "相比其他方案的优势？",
                    "技术创新体现在哪里？",
                    "请介绍项目创新点",
                    "技术突破有哪些？",
                    "项目的技术特色？",
                    "创新技术方案？",
                    "技术先进性体现？"
                ],
                "answer_variations": [
                    "项目技术创新与先进性主要体现在三方面：轻量化部署(DeepSeek-7B采用4bit量化+LoRA微调，普通GPU环境即可运行)、高效实时性(YOLO检测+状态机帧比例判断替代纯大模型决策，减少GPU负载)、智能记忆交互(RAG记忆层实现历史数据结构化管理，支持灵活查询)。",
                    "技术优势：1)资源优化-4bit量化+LoRA微调降低硬件门槛；2)效率提升-分级处理机制仅在高危时调用大模型；3)智能增强-状态机帧比例分析+RAG记忆层支持历史追溯与智能问答，提升系统实用性。",
                    "创新点：多模型协同架构(视觉检测+语言生成)、置信度阈值过滤(0.75减少误报)、状态机帧比例验证(≥80%阈值确保真实性)、轻量化大模型部署(4bit+LoRA)、智能记忆系统(RAG)五大技术特色。",
                    "技术先进性：通过YOLO置信度阈值(0.75)和状态机帧比例双重验证确保准确性，4bit量化使大模型可在消费级硬件运行，RAG记忆实现历史数据智能管理，整体方案在精度、效率和成本间取得良好平衡。",
                    "独特技术方案：计算机视觉与大语言模型结合，置信度过滤与状态机帧比例验证双重保障，量化微调实现轻量化部署，检索增强支持智能记忆，形成完整的技术创新体系。",
                    "技术创新：1)多技术融合架构 2)帧比例风险评估算法 3)轻量化大模型部署 4)智能记忆检索系统 5)实时高效处理流程，五大创新点提升系统性能。",
                    "技术突破：将传统的连续时间判断改进为帧比例统计，大幅降低误报率；通过4bit量化+LoRA微调实现大模型在普通设备的部署；利用RAG技术实现历史数据的智能管理。",
                    "创新特性：帧比例风险评估机制、轻量化大模型部署方案、多模型协同处理架构、智能记忆检索系统、实时高效处理流程，五大特性构成技术核心竞争力。",
                    "技术亮点：基于帧比例的状态机算法提高检测准确性，4bit量化技术降低硬件要求，LoRA微调提升模型适应性，RAG记忆实现智能数据管理。",
                    "创新优势：相比传统方案，本项目通过多技术融合和算法优化，在准确性、效率和成本三个方面实现显著提升，具备更好的实用性和推广价值。"
                ]
            },

            "application_scenarios": {
                "core_question": "应用场景",
                "question_variations": [
                    "项目适合在哪些场景使用？",
                    "这个摔倒检测系统能应用在哪里？",
                    "项目的目标使用场景有哪些？",
                    "系统适用于什么环境？",
                    "可以在哪些地方部署这个项目？",
                    "使用场景范围是什么？",
                    "适合在什么场合应用？",
                    "目标应用领域有哪些？",
                    "系统部署的典型场景是什么？",
                    "适用于哪些具体场合？",
                    "项目的应用场合？",
                    "适合在什么地方使用？",
                    "应用领域有哪些？",
                    "部署场景是什么？",
                    "使用环境有哪些？",
                    "适合哪些场所？",
                    "请介绍应用场景",
                    "目标使用场合？",
                    "适用的环境？",
                    "应用范围有哪些？",
                    "部署的典型场合？"
                ],
                "answer_variations": [
                    "项目聚焦实时安全监护场景，核心应用包括：养老场景(养老院老人安全监控、居家独居老人防护)、校园场景(操场、宿舍楼下等公共区域安全监测)、工业场景(工厂车间、仓储区作业安全防护)、家庭场景(居家老人、儿童日常安全监护)。",
                    "适用场所：老年人照护机构、医院康复科室、社区居家环境、学校运动区域、工业生产场所、家庭生活空间等存在摔倒风险且需要及时响应的各类环境。",
                    "目标场景：养老院卧室与活动区、医院病房与走廊、居家老人生活空间、学校操场与楼梯、工厂作业区域、社区公共活动场所等对安全监护有需求的场地。",
                    "应用领域：1)医疗康养-老人病人安全监控 2)教育机构-学生活动安全 3)工业生产-员工作业安全 4)家庭生活-成员日常安全 5)公共场所-应急安全防护。",
                    "部署环境：需要实时安全监控的室内外场所，特别关注老年人、病人、儿童、作业人员等高风险群体的活动区域，提供24小时不间断的安全保障服务。",
                    "典型应用：养老机构的老人活动区、医院康复科的病人监护区、学校体育场馆的运动区域、工厂生产车间的作业区域、社区公共活动场所的安全监控。",
                    "适用场景：1)老年人独居环境 2)医疗机构病房区域 3)学校体育教学场所 4)工业生产作业场地 5)社区公共活动空间 6)家庭日常生活环境。",
                    "部署场合：养老院、医院、学校、工厂、社区、家庭等需要对人员安全进行实时监控的各种室内外环境。",
                    "应用范围：涵盖医疗康养、教育培训、工业生产、社区服务、家庭生活等多个领域，为各类高风险群体提供安全监护服务。",
                    "使用环境：包括但不限于养老机构、医疗机构、教育机构、工业企业、社区服务中心、家庭住宅等需要人员安全监控的场所。"
                ]
            },

            "video_storage": {
                "core_question": "历史监控视频",
                "question_variations": [
                    "历史监控视频能存多久？怎么查看？",
                    "监控视频的存储和查看规则是什么？",
                    "如何调取之前的监控画面？",
                    "视频存储策略是怎样的？",
                    "历史录像能保存多长时间？",
                    "怎么查看过往的监控记录？",
                    "视频数据的管理规则是什么？",
                    "监控录像的存取机制如何？",
                    "历史视频如何检索和播放？",
                    "视频存储周期是多长？",
                    "视频能保存多久？",
                    "如何查看历史视频？",
                    "录像存储规则？",
                    "视频管理策略？",
                    "历史录像查看方法？",
                    "视频存储时间？",
                    "请介绍视频存储",
                    "录像检索方式？",
                    "视频数据管理？",
                    "历史视频调取？",
                    "录像保存期限？"
                ],
                "answer_variations": [
                    "历史监控视频遵循按需存储规则：后端按时间段切片存储至服务器，默认保留1-2天数据，超期自动清理节省空间；用户在Web前端历史视频模块选择摄像头与时间段，系统从服务器调取对应视频支持在线播放与进度拖动。",
                    "视频存储：采用循环存储策略，保留最近1-2天的监控录像，自动覆盖旧数据；查看方式：前端界面提供时间选择器，用户指定时间段后系统检索并播放对应视频文件。",
                    "存储机制：视频数据按时间分段存储，默认48小时保留期，支持按需扩展；检索播放：用户在前端选择日期时间范围，系统匹配并加载相应视频片段，提供播放控制功能。",
                    "视频管理：1)存储周期1-2天 2)自动清理超期文件 3)按时间分段组织 4)前端按时间检索 5)在线流畅播放 6)支持进度控制，形成完整的视频管理体系。",
                    "规则说明：监控视频保存48小时，超时自动删除；查看方法：登录Web系统进入历史视频页面，选择摄像头和起止时间，即可观看对应时间段的录像回放。",
                    "视频存储方案：采用时间切片存储技术，将连续视频流分割为固定时长片段，默认保留最近48小时数据，支持按时间点精准检索和播放。",
                    "录像管理：基于文件系统的视频数据管理，按日期和时间组织存储结构，提供高效的文件检索和流媒体播放支持。",
                    "存储策略：循环覆盖存储机制，固定存储容量，新数据自动覆盖最旧数据，确保存储空间高效利用的同时保留最近期的监控记录。",
                    "视频检索：支持按摄像头、日期、时间范围等多维度条件检索历史录像，提供时间轴导航和关键帧预览功能，方便用户快速定位目标片段。",
                    "播放功能：基于HTML5视频播放技术，支持进度拖动、播放暂停、倍速播放等控制功能，提供流畅的历史视频观看体验。"
                ]
            },

            "detection_display": {
                "core_question": "前端检测显示控制",
                "question_variations": [
                    "网页上能隐藏检测框和标签吗？",
                    "如何控制监控画面中检测信息的显示？",
                    "前端有没有隐藏检测数据的功能？",
                    "检测信息的显示可以关闭吗？",
                    "怎么切换检测框的显示状态？",
                    "能否隐藏YOLO的识别结果？",
                    "检测可视化如何控制？",
                    "界面上的识别信息能隐藏吗？",
                    "如何关闭检测框显示？",
                    "检测结果显示可以调整吗？",
                    "检测信息能隐藏吗？",
                    "如何控制检测显示？",
                    "检测框能关闭吗？",
                    "识别结果能隐藏吗？",
                    "检测可视化设置？",
                    "显示控制功能？",
                    "请介绍检测显示",
                    "检测信息显示控制？",
                    "识别框显示设置？",
                    "检测结果可视化？",
                    "显示选项有哪些？"
                ],
                "answer_variations": [
                    "Web前端实时监控画面固定显示YOLO检测框、标签及置信度信息，为用户提供完整的检测可视化效果，不支持隐藏检测信息功能。",
                    "显示策略：监控界面持续展示完整的检测信息包括识别边框、类别标签和置信度分数，确保用户能够实时了解系统检测状态和分析结果。",
                    "界面特性：实时监控页面默认显示所有YOLO识别细节，包括检测框、标签文字和置信度数值，为用户提供全面的视觉分析支持。",
                    "功能设计：系统采用固定显示检测信息的策略，在监控画面中始终呈现识别结果，确保用户能够准确掌握当前的人员状态和检测情况。",
                    "可视化方案：前端监控界面集成完整的检测信息展示，包括目标边框、状态标签和可信度分数，为用户提供清晰直观的监控体验。",
                    "显示配置：系统采用始终显示检测信息的方案，不提供隐藏选项，确保用户在任何时候都能看到完整的识别结果和分析数据。",
                    "界面设计：监控画面集成检测可视化元素，包括边界框、类别标签、置信度数值，通过固定显示策略提供一致的视觉体验。",
                    "显示特性：实时视频流叠加检测信息图层，持续展示YOLO识别结果，帮助用户直观了解系统运行状态和检测准确性。",
                    "可视化策略：采用全时显示方案，监控画面始终包含检测框、标签文字和置信度信息，不提供隐藏或关闭选项。",
                    "界面实现：基于Canvas技术的检测信息叠加显示，在视频流上实时绘制识别结果，确保用户获得完整的视觉反馈信息。"
                ]
            },

            "alert_query": {
                "core_question": "历史告警查询",
                "question_variations": [
                    "怎么查看之前的高危告警记录？",
                    "如何查询历史告警的详细信息？",
                    "历史告警数据能查多久的？",
                    "过往告警记录怎么检索？",
                    "如何查看历史安全事件？",
                    "告警历史查询功能如何使用？",
                    "能查询多长时间内的告警记录？",
                    "历史事件检索方法是什么？",
                    "怎么查找之前的危险事件？",
                    "告警记录保存多久？如何查看？",
                    "历史告警如何查询？",
                    "告警记录查看方法？",
                    "历史事件检索？",
                    "告警数据查询？",
                    "如何查看过往告警？",
                    "历史记录查询功能？",
                    "请介绍告警查询",
                    "事件记录检索？",
                    "告警历史查看？",
                    "历史数据查询方式？",
                    "过往事件查询方法？"
                ],
                "answer_variations": [
                    "历史告警查询通过Web前端告警信息模块操作：进入前端后点击历史告警选项查看所有存储记录；支持按时间范围、地点、告警状态筛选，点击单条记录查看详情(时间、地点、帧比例分析结果、告警内容)；数据与RAG记忆层同步，可查询所有历史高危事件数据。",
                    "查询方法：登录系统→进入告警管理→选择历史查询→设置筛选条件(时间、位置、事件类型)→查看结果列表→点击详情查看完整信息(含帧比例数据)，支持多维度的历史数据检索与分析。",
                    "功能说明：提供完整的历史告警查询能力，用户可按照时间、地点、事件类型等条件过滤记录，查看每条告警的详细信息和处理状态，数据永久保存除非手动清理。",
                    "检索体系：基于RAG记忆层的结构化存储，实现高效的历史告警查询，支持条件筛选、关键字搜索、时间范围选择等多种检索方式，提供完整的告警历史追溯能力。",
                    "查询机制：前端界面集成历史告警查询模块，连接后端RAG数据库，用户可通过多种维度检索过往事件，查看详细的事件记录和处理信息，支持数据导出和统计分析。",
                    "查询功能：支持按时间范围、监控位置、事件类型、处理状态等多条件组合查询，提供列表视图和详情视图两种展示方式，方便用户快速定位目标记录。",
                    "检索能力：基于RAG向量数据库的语义检索功能，支持自然语言查询和关键词搜索，能够快速找到相关的历史告警记录。",
                    "查询界面：提供直观的筛选控件和搜索框，支持时间选择器、地点下拉列表、事件类型复选框等多种查询条件设置方式。",
                    "数据展示：查询结果以表格形式展示基本信息，点击详情可查看完整的事件记录，包括时间、地点、帧比例数据、告警内容等详细信息。",
                    "查询特性：支持多条件组合筛选、提供关键字搜索功能、具备数据导出能力、实现分页浏览界面，四大特性提升查询体验。"
                ]
            },

            "alert_logic": {
                "core_question": "告警生成逻辑",
                "question_variations": [
                    "项目怎么判断并生成告警？",
                    "满足什么条件会触发高危告警？",
                    "告警信息是怎么生成和推送的？",
                    "告警触发的条件是什么？",
                    "如何确定需要发送告警？",
                    "告警判断的标准有哪些？",
                    "什么情况下会产生告警？",
                    "告警生成的规则是什么？",
                    "触发告警的完整流程是什么？",
                    "告警机制如何工作？",
                    "告警如何触发？",
                    "告警生成逻辑？",
                    "告警触发条件？",
                    "告警判断标准？",
                    "告警产生机制？",
                    "告警工作流程？",
                    "请介绍告警逻辑",
                    "告警触发机制？",
                    "告警生成过程？",
                    "告警判断逻辑？",
                    "告警产生流程？"
                ],
                "answer_variations": [
                    "告警生成遵循多环节校验逻辑：触发条件为YOLO检测到置信度>0.75的Fall Detected且状态机统计10秒内Fall Detected帧比例≥80%；生成过程为逻辑层将事件信息(时间、地点、帧比例分析结果)格式化为Prompt，传入DeepSeek-7B生成标准化告警文案；推送方式为告警结果实时推送至Web前端实时告警模块，同时存入RAG记忆层。",
                    "告警机制：通过YOLO检测(置信度阈值0.75)识别摔倒状态，状态机验证帧比例风险(10秒内≥80% Fall Detected)，确认高危事件后格式化数据传递大模型生成告警文本，实时推送到前端界面并存储至历史数据库。",
                    "判断标准：1)视觉检测-置信度超过0.75的摔倒识别 2)持续验证-状态机10秒内Fall Detected帧比例≥80% 3)信息生成-大模型格式化输出 4)结果推送-前端展示与数据存储，四级验证确保告警准确性。",
                    "告警流程：YOLO识别(0.75置信度)→状态机帧比例统计(10秒内≥80% Fall Detected)→数据格式化→大模型处理→前端推送→RAG存储，形成完整的从检测到告警的处理链条。",
                    "工作逻辑：基于双重验证机制，计算机视觉提供初步识别(置信度0.75以上)，状态逻辑确认事件持续性(帧比例≥80%阈值)，语言模型生成友好告警，实现准确可靠的危险事件通知。",
                    "告警触发：需要同时满足两个条件：YOLO检测到高置信度的摔倒状态，且状态机统计显示在检测周期内摔倒帧比例超过设定阈值。",
                    "生成流程：事件检测→数据验证→信息格式化→大模型处理→结果推送→数据存储，六个步骤完成从检测到告警的完整处理。",
                    "判断逻辑：采用多级验证机制，先通过视觉检测识别潜在风险，再通过帧比例分析确认事件持续性，最后通过大模型生成自然语言告警。",
                    "告警规则：基于帧比例统计的风险评估算法，在固定时间窗口内计算摔倒状态的持续程度，只有达到阈值才确认为真实高危事件。",
                    "工作机制：实时监控→状态检测→风险评估→事件确认→告警生成→前端推送，形成闭环的处理流程，确保及时准确的安全告警。"
                ]
            }
        }

        # 告警地点池 - 扩展更多地点
        self.locations = [
            "一楼大厅", "二楼走廊东侧", "三楼卧室A", "康复中心训练区", "养老院201房间",
            "活动室中央", "卫生间门口", "楼梯口转角", "餐厅过道", "花园小径",
            "电梯厅前", "护士站旁边", "康复器材区", "休息区沙发旁", "阳台区域",
            "走廊尽头", "病房卫生间", "活动区角落", "楼梯平台", "门厅入口",
            "治疗室门口", "阅览室角落", "健身房中央", "厨房过道", "后院走廊",
            "日间照料中心", "理疗室内部", "娱乐活动区", "户外休息区", "紧急通道",
            "康复训练室", "老人活动中心", "医疗观察室", "护理站前", "日间休息区",
            "康复游泳池", "物理治疗室", "职业治疗区", "言语治疗室", "心理辅导室",
            "营养餐厅", "多功能活动厅", "康复花园", "阳光房", "休闲阅览区",
            "医疗设备间", "药品储存室", "急救准备室", "隔离观察区", "消毒处理间"
        ]

    def apply_synonym_replacement(self, text, replacement_rate=0.4):
        """应用同义词替换"""
        words = text.split()
        replaced_text = []

        for word in words:
            clean_word = word.strip('.,!?;:""''()[]{}')
            if clean_word in self.synonyms and random.random() < replacement_rate:
                replacement = random.choice(self.synonyms[clean_word])
                # 保持标点符号
                if word != clean_word:
                    replacement = replacement + word[len(clean_word):]
                replaced_text.append(replacement)
            else:
                replaced_text.append(word)

        return ' '.join(replaced_text)

    def generate_qa_pairs(self):
        """生成所有问答对的排列组合 - 扩展至1600个问答对"""
        all_qa_pairs = []

        # 合并身份问题和核心问题
        all_questions = {**self.identity_questions, **self.core_questions}

        for question_key, question_data in all_questions.items():
            question_variations = question_data["question_variations"]
            answer_variations = question_data["answer_variations"]

            # 生成所有排列组合 (20个问题 × 10个答案 = 200个组合)
            combinations = list(itertools.product(question_variations, answer_variations))

            for question, answer in combinations:
                # 对答案进行同义词替换，增加多样性
                enhanced_answer = self.apply_synonym_replacement(answer)

                # 统一使用AI问答助手指令
                qa_pair = {
                    "instruction": self.qa_instruction,
                    "input": question,
                    "output": enhanced_answer
                }
                all_qa_pairs.append(qa_pair)

        return all_qa_pairs

    def generate_alert_samples(self, num_samples=1000):
        """生成多样化的告警训练样本 - 基于帧比例的新逻辑，扩展至1000条"""
        alert_samples = []

        alert_templates = [
            "【高危告警】{time}在{location}检测到人员摔倒，10秒内Fall Detected帧比例达{percentage}%，请立即前往处理！",
            "🚨紧急通知：{time}于{location}发现摔倒事件，10秒内摔倒检测帧占比{percentage}%，建议立即派人查看！",
            "⚠安全警报：{time}{location}监测到摔倒情况，检测周期内摔倒帧比例{percentage}%，请及时安排处置！",
            "‼️紧急情况：{time}在{location}识别到人员跌倒，10秒检测期内摔倒状态占比{percentage}%，需要立即关注！",
            "📢系统告警：{time}{location}检测到摔倒高危事件，帧比例分析结果{percentage}%，请速处理！",
            "🔴高危事件：{time}{location}发生摔倒，检测帧比例{percentage}%，请尽快响应！",
            "🚑急救提醒：{time}在{location}检测到跌倒，帧分析占比{percentage}%，需要紧急援助！",
            "👥人员安全：{time}{location}发现摔倒人员，检测比例{percentage}%，请立即查看！",
            "📋事件报告：{time}于{location}监测到摔倒，帧占比{percentage}%，建议处理！",
            "💡风险提示：{time}在{location}识别摔倒风险，检测比例{percentage}%，请关注！",
            "🔔安全告警：{time}{location}检测到人员摔倒，帧比例{percentage}%，请及时处置！",
            "🚩危险事件：{time}在{location}发现跌倒情况，检测占比{percentage}%，需要关注！",
            "📞紧急呼叫：{time}{location}监测到摔倒事件，帧比例{percentage}%，请速往查看！",
            "👴老人安全：{time}在{location}检测到长者摔倒，帧分析{percentage}%，急需援助！",
            "🏥医疗关注：{time}{location}发生摔倒，检测比例{percentage}%，建议医疗检查！",
            "🚶人员安全告警：{time}{location}识别到跌倒事件，帧比例{percentage}%，请立即查看！",
            "📹监控检测告警：{time}在{location}监测到人员摔倒，检测占比{percentage}%，需要处理！",
            "👵长者安全提醒：{time}{location}发现老人跌倒，帧比例{percentage}%，请速往援助！",
            "🏃运动安全告警：{time}于{location}检测到运动摔倒，帧分析{percentage}%，建议检查！",
            "🆘紧急求助：{time}在{location}识别到人员倒地，检测比例{percentage}%，需要紧急响应！"
        ]

        for i in range(num_samples):
            # 生成随机时间（最近30天内）
            base_time = datetime.now() - timedelta(
                days=random.randint(0, 30),
                hours=random.randint(0, 23),
                minutes=random.randint(0, 59)
            )

            # 生成帧比例数据 (80%-100%之间，符合触发条件)
            percentage = random.randint(80, 100)

            # 生成总检测帧数和Fall Detected帧数
            total_frames = random.randint(30, 60)  # 10秒内检测帧数
            fall_frames = int(total_frames * percentage / 100)

            event_time = base_time.strftime("%H:%M:%S")
            location = random.choice(self.locations)

            # 随机选择告警模板
            template = random.choice(alert_templates)

            # 新的输入格式：包含帧比例信息
            input_text = f"时间：{event_time}，地点：{location}，10秒内总检测{total_frames}帧，其中检测到Fall Detected的帧数比例大于80%"
            output_text = template.format(
                time=event_time,
                location=location,
                percentage=percentage
            )

            alert_samples.append({
                "instruction": self.alert_instruction,
                "input": input_text,
                "output": output_text
            })

        return alert_samples

    def save_dataset(self, dataset, filename, split_ratio=0.8):
        """保存数据集并分割训练集/验证集"""
        # 打乱数据
        random.shuffle(dataset)

        # 分割数据集
        split_index = int(len(dataset) * split_ratio)
        train_data = dataset[:split_index]
        val_data = dataset[split_index:]

        # 保存完整数据集
        with open(filename, 'w', encoding='utf-8') as f:
            json.dump(dataset, f, ensure_ascii=False, indent=2)

        # 保存训练集和验证集
        base_name = filename.replace('.json', '')
        with open(f"{base_name}_train.json", 'w', encoding='utf-8') as f:
            json.dump(train_data, f, ensure_ascii=False, indent=2)

        with open(f"{base_name}_val.json", 'w', encoding='utf-8') as f:
            json.dump(val_data, f, ensure_ascii=False, indent=2)

        return len(dataset), len(train_data), len(val_data)


def main():
    generator = ProjectTrainingDataGenerator()

    print("开始生成训练数据...")

    # 生成问答对数据
    print("生成问答对数据...")
    qa_pairs = generator.generate_qa_pairs()

    # 生成告警数据
    print("生成告警训练数据...")
    alert_samples = generator.generate_alert_samples(1000)  # 生成1000个告警样本

    # 合并所有数据
    all_data = qa_pairs + alert_samples
    random.shuffle(all_data)

    # 保存数据集
    total_size, train_size, val_size = generator.save_dataset(
        all_data, "unified_instruction_training_data.json"
    )

    # 输出统计信息
    print(f"\n=== 数据生成完成 ===")
    print(f"核心问题数量: {len(generator.core_questions)}")
    print(f"身份问题数量: {len(generator.identity_questions)}")
    print(f"问答对样本: {len(qa_pairs)} 条")
    print(f"告警样本: {len(alert_samples)} 条")
    print(f"总数据量: {total_size} 条")
    print(f"训练集: {train_size} 条")
    print(f"验证集: {val_size} 条")

    # 各问题类型的详细统计
    print(f"\n=== 各问题类型统计 ===")
    total_qa_pairs = 0
    all_questions = {**generator.identity_questions, **generator.core_questions}
    for question_key, question_data in all_questions.items():
        question_count = len(question_data["question_variations"]) * len(question_data["answer_variations"])
        total_qa_pairs += question_count
        print(f"{question_data['core_question']}: {question_count} 条")

    print(f"\n问答对总计: {total_qa_pairs} 条")
    print(f"告警数据统计:")
    print(f"  - 地点多样性: {len(generator.locations)} 个不同地点")
    print(f"  - 帧比例范围: 80%-100%")

    # 指令类型统计
    print(f"\n=== 指令类型统计 ===")
    alert_count = sum(1 for item in all_data if item["instruction"] == generator.alert_instruction)
    qa_count = sum(1 for item in all_data if item["instruction"] == generator.qa_instruction)
    print(f"告警指令样本: {alert_count} 条")
    print(f"问答指令样本: {qa_count} 条")
    print(f"告警指令内容: {generator.alert_instruction}")
    print(f"问答指令内容: {generator.qa_instruction}")


if __name__ == "__main__":
    main()